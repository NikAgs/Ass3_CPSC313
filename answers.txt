a.	Because the array is accessed and stored in row major order, each cache miss will add the the 64 byte block that is accessed over the next 7 cache reads of 8 bytes each. Hence, the miss rate is 1/8 = 12.5%.

b.	Now the array is accessed in column major order and stored in row major order. Each row is separated by 8 x 128 = 1024 bytes which corresponds to 16 cache blocks. Thus, when we access a[2][0], we replace the block containing a[0][0]. By the time we access a[0][1], the cached block is long gone. The same applies to a[0][2] and so on. Hence, 100% miss rate.

c.	At every iteration in our nested for loops, we perform 4 cache reads. Because we are still accessing the array in column major order, we would have a 100% miss rate except for the fact that in each iteration we access both a[i][j], a[i][j+1] and a[i+1][j], a[i+1][j+1]. The former access in each pair will add the data accessed by the latter. Hence, 2/4 = 50% miss rate.

d.	this one has 100% miss rate and the concept is simple. We have 2 way set associativity so with 32 cache blocks that means we have 16 sets. 128 is divisible by 16 so that means that elements in the same row will have to belong to the same set. We are impleneting replacement of least used so when we use sum B and add in row major order [0][0] is done with a compulsory miss then same for [1][0] then same for [2][0], BUT we have to delete [0][0] and the 7 other elements that come along b/c our set only has room for 2 lines. This sadly means that by the time we get to [0][1] we have a miss once again. Since our set only has the lines for [3][0] and [4][0]. B/C of this we miss every time.

e.	Four was set associative with 32 cache blocks means that we have 4 cache lines for each of our 8 sets. We are transversing the array in row major order. we ahve 128 cols which is divisble by 8. This means that elements that are in the same row will belong in the same set. So we start indexing from [0][0] here we get [0][1] to [0][7] for "free". Then we do the same for [1][0] and so on. The for cache lines from the first 4 reads will all be in the same set but that set takes 4 lines so we are fine. The next 7 row then are given with no misses. Then we move on the the next row. These will all belong in the same set also the next one from the last. we then have a 1/8 miss rate since the patter just repeats.

f.	The miss rate for an array of int64_t with 4 rows by 120 columns would have a miss rate of 12.5%, 1 in every 8. The misses will all be compulsory in that they occur when a new array index that is not part of the cache is being read. This is because the array will be read from row major order. All that is really important is that values that are on the same row never belong in the same set. This is beacuse 120 is 8 less than 128 which is divisible by 32 (the number of sets). This means that each array indice on the same row will belong to succesive sets. All this means that after reading [0][0] we get [0][1] to [0][7] for "free". then the next read [1][0] we get [1][1] tp [1][7] for "free" and so forth. by the time we finish with the first row the next 7 rows are already in cache and we dont have cache misses. Row 8 will be all cache misses again but we once again get 4*7 free accesses. This means that in the end we have a 1/8 or 12.5% miss rate.

